{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(r\"F:\\project\\train.csv\",dtype={'acoustic_data':np.int16, 'time_to_failure':np.float64},nrows=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r\"C:\\Users\\dbda\\Desktop\\project\\project\\x_train.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\dbda\\Desktop\\project\\project\\y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ave       std   max  min   sum  median       var       cov  \\\n",
      "0            NaN       NaN   NaN  NaN   NaN     NaN       NaN       NaN   \n",
      "1            NaN       NaN   NaN  NaN   NaN     NaN       NaN       NaN   \n",
      "2       8.666667  3.055050  12.0  6.0  26.0     8.0  9.333333  9.333333   \n",
      "3       6.333333  1.527525   8.0  5.0  19.0     6.0  2.333333  2.333333   \n",
      "4       7.000000  1.732051   8.0  5.0  21.0     8.0  3.000000  3.000000   \n",
      "...          ...       ...   ...  ...   ...     ...       ...       ...   \n",
      "299995  4.666667  0.577350   5.0  4.0  14.0     5.0  0.333333  0.333333   \n",
      "299996  5.666667  1.154701   7.0  5.0  17.0     5.0  1.333333  1.333333   \n",
      "299997  6.333333  1.154701   7.0  5.0  19.0     7.0  1.333333  1.333333   \n",
      "299998  7.000000  0.000000   7.0  7.0  21.0     7.0  0.000000  0.000000   \n",
      "299999  6.333333  1.154701   7.0  5.0  19.0     7.0  1.333333  1.333333   \n",
      "\n",
      "        quantile_1  quantile_2  quantile_3  stepsize  \n",
      "0              NaN         NaN         NaN      -6.0  \n",
      "1              NaN         NaN         NaN       2.0  \n",
      "2              7.0         8.0        10.0      -3.0  \n",
      "3              5.5         6.0         7.0       3.0  \n",
      "4              6.5         8.0         8.0       0.0  \n",
      "...            ...         ...         ...       ...  \n",
      "299995         4.5         5.0         5.0       2.0  \n",
      "299996         5.0         5.0         6.0       0.0  \n",
      "299997         6.0         7.0         7.0       0.0  \n",
      "299998         7.0         7.0         7.0      -2.0  \n",
      "299999         6.0         7.0         7.0       NaN  \n",
      "\n",
      "[300000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "x = pd.DataFrame(train1['acoustic_data'].values)\n",
    "y = pd.DataFrame(train1['time_to_failure'].values)\n",
    "#y = pd.DataFrame(y)\n",
    "    \n",
    "y_train['time_to_failure'] = y\n",
    "#print(y_train.head())\n",
    "        \n",
    "X_train['ave'] = x.rolling(window=3).mean()\n",
    "X_train['std'] = x.rolling(window=3).std()\n",
    "X_train['max'] = x.rolling(window=3).max()\n",
    "X_train['min'] = x.rolling(window=3).min()\n",
    "X_train['median'] = x.rolling(window=3).median()\n",
    "X_train['var'] = x.rolling(window=3).var()\n",
    "X_train['sum'] = x.rolling(window=3).sum()\n",
    "X_train['cov'] = train1['acoustic_data'].rolling(window=3).cov()\n",
    "X_train['quantile_1'] = x.rolling(window=3).quantile(0.25)\n",
    "X_train['quantile_2'] = x.rolling(window=3).quantile(0.50)\n",
    "X_train['quantile_3'] = x.rolling(window=3).quantile(0.75)\n",
    "\n",
    "stepsize = np.diff(train1['acoustic_data'])\n",
    "train1 = train1.drop(train1.index[len(train1)-1])\n",
    "train1[\"stepsize\"] = stepsize\n",
    "X_train['stepsize'] = train1[\"stepsize\"]\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ave       std   max  min   sum  median       var       cov  \\\n",
      "0      -6.000000 -6.000000  -6.0 -6.0  -6.0    -6.0 -6.000000 -6.000000   \n",
      "1       2.000000  2.000000   2.0  2.0   2.0     2.0  2.000000  2.000000   \n",
      "2       8.666667  3.055050  12.0  6.0  26.0     8.0  9.333333  9.333333   \n",
      "3       6.333333  1.527525   8.0  5.0  19.0     6.0  2.333333  2.333333   \n",
      "4       7.000000  1.732051   8.0  5.0  21.0     8.0  3.000000  3.000000   \n",
      "...          ...       ...   ...  ...   ...     ...       ...       ...   \n",
      "299995  4.666667  0.577350   5.0  4.0  14.0     5.0  0.333333  0.333333   \n",
      "299996  5.666667  1.154701   7.0  5.0  17.0     5.0  1.333333  1.333333   \n",
      "299997  6.333333  1.154701   7.0  5.0  19.0     7.0  1.333333  1.333333   \n",
      "299998  7.000000  0.000000   7.0  7.0  21.0     7.0  0.000000  0.000000   \n",
      "299999  6.333333  1.154701   7.0  5.0  19.0     7.0  1.333333  1.333333   \n",
      "\n",
      "        quantile_1  quantile_2  quantile_3  stepsize  \n",
      "0             -6.0        -6.0        -6.0      -6.0  \n",
      "1              2.0         2.0         2.0       2.0  \n",
      "2              7.0         8.0        10.0      -3.0  \n",
      "3              5.5         6.0         7.0       3.0  \n",
      "4              6.5         8.0         8.0       0.0  \n",
      "...            ...         ...         ...       ...  \n",
      "299995         4.5         5.0         5.0       2.0  \n",
      "299996         5.0         5.0         6.0       0.0  \n",
      "299997         6.0         7.0         7.0       0.0  \n",
      "299998         7.0         7.0         7.0      -2.0  \n",
      "299999         6.0         7.0         7.0       7.0  \n",
      "\n",
      "[300000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.fillna(method='backfill',axis=1)\n",
    "X_train = X_train.fillna(method='ffill',axis=1)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold=KFold(n_splits=5,random_state=2020)\n",
    "\n",
    "depth_range = [18]\n",
    "minsplit_range = [20,25]\n",
    "minleaf_range = [2,3,5]\n",
    "\n",
    "parameters = dict(min_samples_split=minsplit_range, \n",
    "                  min_samples_leaf=minleaf_range)\n",
    "rfr = RandomForestRegressor(oob_score=True,random_state=2020,max_depth=18)\n",
    "\n",
    "cv = GridSearchCV(rfr,scoring='neg_mean_absolute_error',param_grid=parameters,cv=kfold,verbose=3)\n",
    "\n",
    "y_train = y_train['time_to_failure']\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] min_samples_leaf=2, min_samples_split=20 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=2, min_samples_split=20, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=20 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=2, min_samples_split=20, score=-0.019, total= 1.1min\n",
      "[CV] min_samples_leaf=2, min_samples_split=20 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=2, min_samples_split=20, score=-0.005, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=20, score=-0.020, total= 1.1min\n",
      "[CV] min_samples_leaf=2, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=20, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=25, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=25, score=-0.019, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=25, score=-0.005, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=25, score=-0.019, total= 1.2min\n",
      "[CV] min_samples_leaf=2, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=2, min_samples_split=25, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=20, score=-0.039, total= 1.1min\n",
      "[CV] min_samples_leaf=3, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=20, score=-0.019, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=20, score=-0.005, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=20, score=-0.020, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=20, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=25, score=-0.039, total= 1.1min\n",
      "[CV] min_samples_leaf=3, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=25, score=-0.019, total= 1.1min\n",
      "[CV] min_samples_leaf=3, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=25, score=-0.005, total= 1.2min\n",
      "[CV] min_samples_leaf=3, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=25, score=-0.019, total= 1.1min\n",
      "[CV] min_samples_leaf=3, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=3, min_samples_split=25, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=5, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=20, score=-0.039, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=20, score=-0.019, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=20, score=-0.005, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=20, score=-0.020, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=20 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=20, score=-0.039, total= 1.2min\n",
      "[CV] min_samples_leaf=5, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=25, score=-0.039, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=25, score=-0.019, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=25, score=-0.005, total= 1.2min\n",
      "[CV] min_samples_leaf=5, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=25, score=-0.020, total= 1.1min\n",
      "[CV] min_samples_leaf=5, min_samples_split=25 ........................\n",
      "[CV]  min_samples_leaf=5, min_samples_split=25, score=-0.039, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 34.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=2020, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=18,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=True, random_state=2020,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': [2, 3, 5],\n",
       "                         'min_samples_split': [20, 25]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=18, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=2,\n",
       "                      min_samples_split=25, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=True,\n",
       "                      random_state=2020, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.024137364235548225"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'min_samples_split': 25}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train.to_csv(r\"C:\\Users\\dbda\\Desktop\\project\\x_train.csv\",index=False)\n",
    "y_train.to_csv(r\"C:\\Users\\dbda\\Desktop\\project\\y_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
